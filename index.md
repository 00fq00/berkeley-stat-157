# STAT 157: Introduction to Deep Learning

UC Berkeley, Spring, 2019


## Practical information

- Lectures: TBD
- Location: TBD
- Recitations: TBD
- Location: TBD
- Instructor: Alex Smola, Mu Li
- TAs: TBD
- Grading Policy: TBD
- Office hours:

## Overview

This class provides a practical introduction to deep learning, including
theoretical motivations and how to implement it in practice. As part of the
course we will cover multilayer perceptrons, backpropagation, automatic
differentiation, and stochastic gradient descent. Moreover, we introduce
convolutional networks for image processing, starting from the simple LeNet to
more recent architectures such as ResNet for highly accurate models. Secondly,
we discuss sequence models and recurrent networks, such as LSTMs, GRU, and the
attention mechanism. Throughout the course we emphasize efficient
implementation, optimization and scalability, e.g. to multiple GPUs and to
multiple machines. The goal of the course is to provide both a good
understanding and good ability to build modern nonparametric estimators. The
entire course is based on Jupyter notebooks to allow students to gain experience
quickly. Supporting material can be found at https://diveintodeeplearning.org.


## Prerequisites

Programming in Python (CS 61a or CS/STAT C8 and CS 88), linear algebra (MATH 54,
STAT 89A, or EE 16A), probability (STAT 134, STAT 140, or EE 126), and
statistics (STAT 20, STAT 135, or CS/STAT C100).



## Course Format

The course consists of 2 units of 90 minutes, taught by the instructors, plus
office hours by the instructors and TAs. Evaluation is based on a midterm exam
(20%), homework (30%), attendance (5%), and a research project (60%) which will
be presented in lieu of an end-of-course exam. The research project is evaluated
via organization (10%), mid-project report (15%), presentation (15%), report
(20%).

```eval_rst

.. toctree::
   :maxdepth: 1
   :hidden:

   syllabus
   calendar
   homework
   project
   faq
   units/index

```

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Dropout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import d2l\n",
    "from mxnet import autograd, gluon, init, nd\n",
    "from mxnet.gluon import loss as gloss, nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dropout from Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dropout(X, drop_prob):\n",
    "    assert 0 <= drop_prob <= 1\n",
    "    # In this case, all elements are dropped out.\n",
    "    if drop_prob == 1:\n",
    "        return X.zeros_like()\n",
    "    mask = nd.random.uniform(0, 1, X.shape) > drop_prob\n",
    "    return mask * X / (1.0-drop_prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Sanity Test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[[ 0.  1.  2.  3.  4.  5.  6.  7.]\n",
      " [ 8.  9. 10. 11. 12. 13. 14. 15.]]\n",
      "<NDArray 2x8 @cpu(0)>\n",
      "\n",
      "[[ 0.  0.  0.  0.  8. 10. 12.  0.]\n",
      " [16.  0. 20. 22.  0.  0.  0. 30.]]\n",
      "<NDArray 2x8 @cpu(0)>\n",
      "\n",
      "[[0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "<NDArray 2x8 @cpu(0)>\n"
     ]
    }
   ],
   "source": [
    "X = nd.arange(16).reshape((2, 8))\n",
    "print(dropout(X, 0))\n",
    "print(dropout(X, 0.5))\n",
    "print(dropout(X, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Defining Model Parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_inputs, num_outputs, num_hiddens1, num_hiddens2 = 784, 10, 1024, 2048\n",
    "\n",
    "W1 = nd.random.normal(scale=0.01, shape=(num_inputs, num_hiddens1))\n",
    "b1 = nd.zeros(num_hiddens1)\n",
    "W2 = nd.random.normal(scale=0.01, shape=(num_hiddens1, num_hiddens2))\n",
    "b2 = nd.zeros(num_hiddens2)\n",
    "W3 = nd.random.normal(scale=0.01, shape=(num_hiddens2, num_outputs))\n",
    "b3 = nd.zeros(num_outputs)\n",
    "\n",
    "params = [W1, b1, W2, b2, W3, b3]\n",
    "for param in params:\n",
    "    param.attach_grad()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Define the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_prob1, drop_prob2 = 0.0, 0.0\n",
    "\n",
    "def net(X):\n",
    "    X = X.reshape((-1, num_inputs))\n",
    "    H1 = (nd.dot(X, W1) + b1).relu()\n",
    "    if autograd.is_training():        # Use dropout only when training the model.\n",
    "        H1 = dropout(H1, drop_prob1)  # Add a dropout layer after the first fully connected layer.\n",
    "    H2 = (nd.dot(H1, W2) + b2).relu()\n",
    "    if autograd.is_training():\n",
    "        H2 = dropout(H2, drop_prob2)  # Add a dropout layer after the second fully connected layer.\n",
    "    return nd.dot(H2, W3) + b3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.9413, train acc 0.645, test acc 0.808\n",
      "epoch 2, loss 0.5028, train acc 0.810, test acc 0.845\n",
      "epoch 3, loss 0.4372, train acc 0.837, test acc 0.863\n",
      "epoch 4, loss 0.3904, train acc 0.854, test acc 0.869\n",
      "epoch 5, loss 0.3703, train acc 0.863, test acc 0.865\n",
      "epoch 6, loss 0.3456, train acc 0.872, test acc 0.871\n",
      "epoch 7, loss 0.3291, train acc 0.878, test acc 0.881\n",
      "epoch 8, loss 0.3103, train acc 0.883, test acc 0.886\n",
      "epoch 9, loss 0.2992, train acc 0.888, test acc 0.888\n",
      "epoch 10, loss 0.2893, train acc 0.892, test acc 0.885\n"
     ]
    }
   ],
   "source": [
    "num_epochs, lr, batch_size = 10, 0.5, 256\n",
    "loss = gloss.SoftmaxCrossEntropyLoss()\n",
    "train_iter, test_iter = d2l.load_data_fashion_mnist(batch_size)\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size, params, lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Dropout in Gluon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = nn.Sequential()\n",
    "net.add(nn.Dense(num_hiddens1, activation=\"relu\"),\n",
    "        nn.Dropout(drop_prob1),  # Add a dropout layer after the first fully connected layer.\n",
    "        nn.Dense(num_hiddens2, activation=\"relu\"),\n",
    "        nn.Dropout(drop_prob2),  # Add a dropout layer after the second fully connected layer.\n",
    "        nn.Dense(num_outputs))\n",
    "net.initialize(init.Normal(sigma=0.01))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1, loss 0.8574, train acc 0.677, test acc 0.813\n",
      "epoch 2, loss 0.4920, train acc 0.817, test acc 0.854\n",
      "epoch 3, loss 0.4295, train acc 0.840, test acc 0.861\n",
      "epoch 4, loss 0.3912, train acc 0.854, test acc 0.867\n",
      "epoch 5, loss 6.1379, train acc 0.705, test acc 0.254\n",
      "epoch 6, loss 7.2570, train acc 0.322, test acc 0.522\n",
      "epoch 7, loss 1.4614, train acc 0.476, test acc 0.176\n",
      "epoch 8, loss 1.5300, train acc 0.453, test acc 0.588\n",
      "epoch 9, loss 0.6826, train acc 0.738, test acc 0.770\n",
      "epoch 10, loss 0.5558, train acc 0.794, test acc 0.829\n"
     ]
    }
   ],
   "source": [
    "trainer = gluon.Trainer(net.collect_params(), 'sgd', {'learning_rate': lr})\n",
    "d2l.train_ch3(net, train_iter, test_iter, loss, num_epochs, batch_size,\n",
    "             None, None, trainer)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
